---
title: Basic Inferences
header-includes: \usepackage{color}
output:
  html_document: default
  pdf_document:
    fig_caption: no
---
<style>
table, th, td { text-align:right; }
th, td {padding: 10px;}
</style>

```{r, echo=FALSE, warning=FALSE, message=FALSE}
whichcomp <- strsplit(getwd(),"/")[[1]][3]
load(paste0("c:/users/", whichcomp, "/Dropbox/teaching/Resma3/Resma3.RData"))
library(knitr)
library(wolfr)
opts_chunk$set(fig.width=6, fig.align = "center", 
      out.width = "70%", warning=FALSE, message=FALSE)
library(ggplot2)
library(grid)
options(scipen = 999)
```
`r hl()$basefontsize()`

In this section we will discuss some of the standard (frequentist) methods in Statistics.

## Inference for a Population Mean

The basic R command for inference for a population mean is *t.test*.

### Confidence Intervals

#### **Example**: Mothers Cocain Use and Babies Health

Chasnoff and others obtained several measures and responses for newborn babies whose mothers were classified by degree of cocain use.

The study was conducted in the Perinatal Center for Chemical Dependence at Northwestern University Medical School. The measurement given here is the length of the newborn.

Source: Cocaine abuse during pregnancy: correlation between prenatal care and perinatal outcome  
Authors: SN MacGregor, LG Keith, JA Bachicha, and IJ Chasnoff  
Obstetrics and Gynecology 1989;74:882-885

Let's ignore the drug status for the moment and find a $90\%$ confidence interval for the length of a newborn baby

```{r}
round(as.numeric(t.test(mothers$Length)$conf.int), 2)
```

The assumptions for this method are:

-  data comes from a normal distribution  
-  or data set is large enough

Let's check:

```{r}
df <- data.frame(x=mothers$Length)
ggplot(df, aes(sample=x)) +
  stat_qq() + stat_qq_line()
```

This is fine. 

### Hypothesis Testing

#### **Example**: Resting Period of Monarch Butterflies

Some Monarch butterflies fly early in the day, others somewhat later. After the flight they have to rest for a short period. It has been theorized that the resting period (RIP) of butterflies flying early in the morning is shorter because this is a thermoregulatory mechanism, and it is cooler in the mornings. The mean RIP of all Monarch butterflies is 133 sec. Test the theory at the 10% level.

Research by Anson Lui, Resting period of early and late flying Monarch butterflies Danaeus plexippus, 1997

1. Parameter: mean $\mu$  
2. Method: 1-sample t  
3. Assumptions: normal data or large sample  
4. $\alpha = 0.1$  
5. $H_0: \mu =133$ (RIP is the same for early morning flying butterflies as all others)  
6. $H_0: \mu <133$ (RIP is the shorter for early morning flying butterflies)   
7. 

```{r, warning=FALSE}
t.test(butterflies$RIP.sec., 
       mu=133, 
       alternative = "less")$p.value
```

8.  $p = 0.0558 < \alpha = 0.1$, so we reject the null hypothesis  
9. It appears the resting time is somewhat shorter, but the conclusion is not a strong one. 

Checking the assumption:

```{r}
df <- data.frame(x=butterflies$RIP.sec.)
ggplot(df, aes(sample=x)) +
  stat_qq() + stat_qq_line()
```

looks good.

### Power Calculations

The power of a test is the probability to correctly reject the null if the null is false. The power will always depend on an assumed value for the mean.

Let's say the true mean resting period is 120.7 seconds. What was the probability that Anson's experiment would have detected this? That is, what is 

$$
P_{\mu=120.7}(\text{reject null})
$$

First we need to find the critical region of this test, so we know what *reject H~0~* actually means. Now if the test is done at the 5% level we reject the null if the p value is less than 0.05. How can we find out for what value of the sample mean this will happen? Let's do the following:

-  generate data from a normal distribution with mean $\mu$, standard deviation as in our data and the same number of observations

-  find the p value and check whether it is < 0.05

-  repeat many times and find average.

- use trial and error on $\mu$ until the probability is (about) 0.05:

```{r}
mean.M <- function(M, true.mu=133) {
  B <- 10000
  pvals <- rep(0, B)
  for(i in 1:B) {
    x <- rnorm(length(butterflies$RIP.sec.), M, 
               sd(butterflies$RIP.sec.))
    pvals[i] <- t.test(x, mu=true.mu, 
       alternative = "less")$p.value
  }
  1-sum(pvals<0.05)/B
}
mean.M(120)
mean.M(110)
mean.M(115)
```

just about right! We now know that "reject H~0~" means $\bar{X}<115$.

Now we turn this around: if the true mean where 120.5, what is the probability that we would reject the null, that is get a sample mean of 115 or less? Actually, we can again use the same routine:

```{r}
mean.M(115, true.mu = 120.7)
```

Of course here this can also be done analytically: 
$$
\begin{aligned}
&P_{\mu=133}(\text{ reject null })    = \\
&P_{\mu=133}(\bar{X}< \text{crit}) = 0.05 \\
\end{aligned}
$$
Now $\bar{X} \sim N(133, s/\sqrt{40})$, so

```{r}
crit <- qnorm(0.05, 133, sd(butterflies$RIP.sec.)/sqrt(40))
crit
```

(Actually the distribution is *t*, not a normal, but we will ignore this here)

and now

$$
\begin{aligned}
&P_{\mu=120.7}(\text{ reject null })    = \\
&P_{\mu=120.7}P(\bar{X}<124.06)  =\\
\end{aligned}
$$

```{r}
pnorm(124.06, 120.7, sd(butterflies$RIP.sec.)/sqrt(40))
```

and sof course we get the same answer.

`r hl()$hr()`

There are also a number of packages that can be used to find the power of a test:

```{r}
library(pwr)
pwr.t.test(40, d=(120.7-133)/sd(butterflies$RIP.sec.),
           alternative = "less",
           type = "one.sample")
```

Usually one wants to study the power for a whole range of values. This is done by drawing a *power curve*:

```{r}
x <- seq(110, 133, 0.1)
y <- x
for(i in seq_along(x))
  y[i] <- pwr.t.test(40,
          d=(x[i]-133)/sd(butterflies$RIP.sec.),
           alternative = "less",
           type = "one.sample")$power
df <- data.frame(Mean=x, Power=y)
ggplot(df, aes(Mean, Power)) +
  geom_line(col="blue", size=1.2)
```


### Sample Size

so, if the true mean resting period is 120.7 seconds the power is 72%. What sample size would we need to have a power of 95%

```{r}
round(pwr.t.test(power=0.95,
      d=(120.7-133)/sd(butterflies$RIP.sec.),
      alternative = "less",
      type = "one.sample")$n)
```

The sample size issue also arises when we want to find a confidence interval. Here the number that corresponds to the power is the *error* E, that is half the length of the interval. 

Analytically we find

$$
\begin{aligned}
&\bar{X} \pm z_{\alpha/2}s/\sqrt{n}  \\
&E= z_{\alpha/2}s/\sqrt{n}\\
&n    = (\frac{z_{\alpha/2}s}{E})^2 \\
\end{aligned}
$$
let's see

```{r}
I <- t.test(butterflies$RIP.sec.)$conf.int
diff(I)/2
```

so a 95% confidence interval has an error of 11. If we wanted an error of 5 we would need a sample size of

```{r}
round((qnorm(0.975)*sd(butterflies$RIP.sec.)/5)^2)
```

## Inference for a Population Proportion

The R routine for inference for a proportion (or a probability or a percentage) is *binom.test*. This implements a method by Clopper and Pearson (1934). This method is exact and has no assumptions.

**Note** The formula discussed in many introductory statistic courses for the confidence interval is 

$$
\hat p \pm \sqrt{\frac{\hat p (1-\hat p)}{n} } 
$$

where $\hat p$ is the proportion of success. This leads to confidence intervals that are now known to be quite wrong, and so this method should not be used anymore. The same is true for the corresponding hypothesis test. This method (actually a slight improvement due to Wilson (1927)) is implemented in R by *prop.test*.

#### **Example**: Jon Kerrichs Coin

The South African Jon Kerrich spent some time in a German prisoner of war camp during world war I. He used his time to flip a coin 10000 times, resulting in 5067 heads.

Test at the 5% level of significance whether 5067 heads in 10000 flips are compatible with a fair coin. 

1. Parameter: proportion $\pi$   
2. Method: exact binomial   
3. Assumptions: None   
4. $\alpha = 0.05$   
5. $H_0: \pi = 0.5$ (50% of flips result in "Heads", coin is fair)   
6. $H_a: \pi \ne 0.5$ (coin is not fair)   
7. 

```{r}
binom.test(x = 5067, n = 10000)$p.value 
```
  
8. $p = 0.1835 > \alpha=0.05$, so we fail to reject the null hypothesis.  
9. it appears Jon Kerrich's coin was indead fair.

#### **Example**: Sample Size for Polling

Say some polling institute wants to conduct a poll for the next election for president. They will then find a 95% confidence interval and they want this interval to have an error of 3 percentage points (aka $\pm 0.03$). What sample size do they need?

In Amercian politics the two parties are always very close, so in a poll with n people about n/2 will vote for one or the other party. Let's do a little trial and error:

```{r}
n <- 100
diff(as.numeric(binom.test(n/2, n)$conf.int)/2)
```

Now that is to large, so

```{r}
n <- 200
diff(as.numeric(binom.test(n/2, n)$conf.int)/2)
n <- 400
diff(as.numeric(binom.test(n/2, n)$conf.int)/2)
n <- 800
diff(as.numeric(binom.test(n/2, n)$conf.int)/2)
n <- 1200
diff(as.numeric(binom.test(n/2, n)$conf.int)/2)
n <- 1100
diff(as.numeric(binom.test(n/2, n)$conf.int)/2)
n <- 1050
diff(as.numeric(binom.test(n/2, n)$conf.int)/2)
```

There is something quite remarkable about this result!

## Correlation 

#### **Example** UPR Admissions data

What are the correlations between the various variables?

```{r}
head(upr, 2)
```

Let's take out the those variables that are either not numerical or not useful for prediction:

```{r}
x <- upr[, -c(1, 2, 3, 4, 13, 14, 16)]
head(x, 2)
```

```{r}
round(cor(x, use = "complete.obs") ,3)
```

#### **Example**: The 1970's Military Draft

In 1970, Congress instituted a random selection process for the military draft. All 366 possible birth dates were placed in plastic capsules in a rotating drum and were selected one by one. The first date drawn from the drum received draft number one and eligible men born on that date were drafted first. In a truly random lottery there should be no relationship between the date and the draft number.

Question: **was the draft was really "random"?**

Here we have two quantitative variables, so we start with the scatterplot:

```{r}
plot(draft$Draft.Number, draft$Day.of.Year,
     pch=20,
     xlab="Day of Year",
     ylab="Draft Number")
```

and this does not look like there is a problem with independence.

However:

1) Parameter: Pearson's correlation coefficient $\rho$
2) Method: Test for Pearson's correlation coefficient $\rho$
3) Assumptions: relationship is linear and that there are no outliers.
4) $\alpha = 0.05$  
5) $H_0: \rho =0$ (no relationship between Day of Year and Draft Number) 
6) $H_a: \rho \ne 0$ (some relationship between Day of Year and Draft Number) 
7) 
```{r}
cor.test(draft$Draft.Number, draft$Day.of.Year)$p.value
```

8) $p=0.0000 <\alpha = 0.05$, so we reject the null hypothesis,
9) There is a statistically significant relationship between Day of Year and Draft Number.  

## Categorical Data Analysis - Tests for Independence

#### **Example**: Drownings in Los Angeles

Data is from O'Carroll PW, Alkon E, Weiss B. Drowning mortality in Los Angeles County, 1976 to 1984, JAMA, 1988 Jul 15;260(3):380-3.

Drowning is the fourth leading cause of unintentional injury death in Los Angeles County. They examined data collected by the Los Angeles County Coroner's Office on drownings that occurred in the county from 1976 through 1984. There were 1587 drownings (1130 males and 457 females) during this nine-year period

```{r}
drownings
```

Here we have two categorical variables (Method of Drowning and Gender), both categorical. We want to know whether the variables are independent. The most popular method of analysis for this type of problem is **Pearson's chi square test of independence**. It is done with the command *chisq.test* and it has the assumption of no expected counts less than 5.

1. Parameters of interest: measure of association  
2. Method of analysis: chi-square test of independence   
3. Assumptions of Method: all expected counts greater than 5   
4. Type I error probability $\alpha$=0.05   
5. H~0~: Classifications are independent = there is no difference in the method of drowning between men and women.  
6. H~a~: Classifications are dependent = there is some difference in the method of drowning between men and women.   
7. 

```{r}
chisq.test(drownings)
```


8. p = 0.000 < $\alpha$=0.05, we reject the null hypothesis, there is a statistically significant difference between men and women and where they drown. 

Let's see whether there is a problem with the assumptions:

```{r}
round(chisq.test(drownings)$expected, 1)
```

and we see that the expected counts of Pails, basins, toilets and Female is 3.2. In real life this would be considered ok, but it would also be easy to fix:

```{r}
newmale <- c(drownings[1:7, 1], 7+40)
newfemale <- c(drownings[1:7, 2], 4+12)
newdrown <- cbind(newmale, newfemale)
newdrown
out <- chisq.test(newdrown) 
round(out$expected, 1)
round(out$p.value, 4)
```
 